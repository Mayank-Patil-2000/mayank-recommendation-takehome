<<<<<<< HEAD
## Link to the video walkthrough -> https://youtu.be/WwbUOHW1B6c

## Backend
## Setup Instructions

1. Create a virtual environment:
   ```
   python -m venv venv
   ```

2. Activate the virtual environment:
   - Windows: `venv\Scripts\activate`
   - macOS/Linux: `source venv/bin/activate`

3. Install dependencies:
   ```
   pip install -r requirements.txt
   ```

4. Create a `.env` file in the backend directory with your OpenAI API key:
   ```
   OPENAI_API_KEY="your_openai_api_key_here"
   MODEL_NAME=gpt-4
   MAX_TOKENS=1000
   TEMPERATURE=0.7
   DATA_PATH=data/products.json
   MONGO_URI=mongodb+srv://mmpatil:PgKETkzdgBa6jB8N@recommendation-takehome.n6zbeey.mongodb.net/
   DB_NAME=recommendation_db
   ```

5. Run the application:
   ```
   uvicorn app:app --host 0.0.0.0 --port 5000 --reload
   ```

## Frontend
## Setup Instructions

1. Install dependencies:
   ```
   npm install
   ```

2. Start the development server:
   ```
   npm start
   ```

##  Backend Implementation

1. My primary contribution lies in building a reliable and intelligent recommendation pipeline within LLMService. 
2. I developed a strict matches_preferences filtering function to ensure that only products matching the user's selected price range, categories, and brands are passed to the LLM. This dramatically reduces noise and guides the model toward high-quality suggestions.
3. The prompt I designed reflects both explicit user preferences and implicit interests derived from browsing history. It includes detailed instructions to avoid hallucinations, limit results to the provided product catalog, and return structured JSON objects. 
4. To validate the model's response, I enhanced _parse_recommendation_response with comprehensive checks, ensuring each recommendation contains a valid product_id, product_name, explanation, and score, while discarding duplicates or mismatches.
5. I added Robust error handling throughout the backend to capture and surface OpenAI API issues, malformed JSON, or invalid entries without crashing the pipeline, improving overall reliability and debuggability.


## Frontend Architecture 

On the frontend, I transformed the boilerplate into a polished, modular interface with the following key improvements:

1. Start the development server: Authentication System: Built secure login and registration flows with persistent sessions using localStorage. The login state is preserved across page refreshes, and the UI conditionally renders the dashboard or authentication modals based on user status.

2. Dynamic Auth Toggle: Implemented a seamless switch between login and registration in a unified modal, enhancing the user onboarding experience.

3. Interactive Catalog:
   1. Dynamic search, sorting, and brand filtering.
   2. Viewed products are visually highlighted using the /add-viewed API route.

4. Enhanced Browsing History:
   1. Implemented Tooltip-based hover previews to give context-rich browsing without clutter.
   2. Option to clear history.

5. Recommendations UI: Made sure the product cards with explanations generated by the LLM are Clearly structured.

6. Improved Styling & UX: Styled the entire app with CSS-in-JS principles. I made the Components responsive, with soft color palettes, hover effects, and subtle transitions for better usability.

## Challenges I Faced

1. LLM Hallucinations and Product Validation:

   1. One of the biggest challenges was controlling the behavior of gpt4, which often hallucinated product recommendations.
   2. To resolve this, I implemented a strict matches_preferences() filter that pruned the catalog based on the user’s selected categories, brands, and price range.
   3. I also engineered a very explicit prompt instructing the LLM to only recommend items from the provided catalog. On top of that, I enforced a second layer of validation in the _parse_recommendation_response() method to match both product_id and product_name exactly against entries from products.json. This greatly improved result consistency.

2. Malformed JSON Output from LLM

   1. At times, the LLM returned JSON arrays with syntax issues—missing commas, trailing characters, or incorrectly quoted values.
   2. I addressed this by using regex (re.search(r'\[\s*{.*?}\s*]', ..., re.DOTALL)) to isolate the JSON block from the raw response, then cleaned it using additional regex transformations (removing trailing commas).
   3. I also wrapped the parsing logic in a try/except block to ensure the application wouldn't break and instead return meaningful fallback error messages.

3. Session State Loss on Page Refresh

   1. Initially, the user’s session was lost after a page refresh because userEmail was stored only in React state.
   2. To persist the login session, I stored userEmail in localStorage during login, initialized the app’s state using useState(() => localStorage.getItem("userEmail")), and ensured that logout would clear this value. This preserved the session across refreshes.

4. State Coordination Across Components

Managing shared state between components like Catalog, BrowsingHistory, and Recommendations was tricky.
=======
# i95dev AI Engineering Intern - Take-Home Assignment
## AI-Powered Product Recommendation Engine

### Overview

Welcome to the i95dev AI Engineering Intern take-home assignment! This project is designed to evaluate your skills in working with LLMs, prompt engineering, and full-stack development in an eCommerce context.

Your task is to build a simplified product recommendation system that leverages LLMs to generate personalized recommendations based on user preferences and browsing history. This system should demonstrate your ability to effectively engineer prompts, build APIs, and create a functional frontend interface.

### Project Requirements

#### Backend (Python)
- Develop a REST API using Flask that interfaces with an LLM (OpenAI GPT-3.5-turbo or similar)
- Implement prompt engineering to optimize product recommendations based on user preferences
- Create endpoints for:
  - Accepting user preference data
  - Processing browsing history
  - Returning personalized product recommendations with explanations

#### Frontend (React)
- Build a clean interface showing the product catalog
- Implement a user preference form to capture interests (e.g., preferences for categories, price ranges, styles)
- Create a browsing history simulation (users can click on products to add them to history)
- Display personalized recommendations with reasoning from the LLM

### Starter Kit

We've provided a starter kit to help you focus on the core technical challenges rather than boilerplate setup. The kit includes:

#### Backend Structure
```
backend/
│
├── app.py               # Main Flask application
├── requirements.txt     # Python dependencies
├── config.py            # Configuration (add your API keys here)
├── data/
│   └── products.json    # Sample product catalog
│
├── services/
│   ├── __init__.py
│   ├── llm_service.py   # Service for LLM interactions (implement this)
│   └── product_service.py  # Service for product data operations
│
└── README.md            # Backend setup instructions
```

#### Frontend Structure
```
frontend/
│
├── public/
│   └── index.html
│
├── src/
│   ├── App.js           # Main application component
│   ├── index.js         # Entry point
│   ├── components/
│   │   ├── Catalog.js   # Product catalog display (implement this)
│   │   ├── UserPreferences.js  # Preference form (implement this)
│   │   ├── Recommendations.js  # Recommendations display (implement this)
│   │   └── BrowsingHistory.js  # Browsing history component (implement this)
│   │
│   ├── services/
│   │   └── api.js       # API client for backend communication
│   │
│   └── styles/
│       └── App.css      # Styling
│
├── package.json         # NPM dependencies
└── README.md            # Frontend setup instructions
```

### Sample Dataset

We've provided a sample product catalog (`products.json`) that contains 50 products across various categories. Each product has the following structure:

```json
{
  "id": "product123",
  "name": "Ultra-Comfort Running Shoes",
  "category": "Footwear",
  "subcategory": "Running",
  "price": 89.99,
  "brand": "SportsFlex",
  "description": "Lightweight running shoes with responsive cushioning and breathable mesh upper.",
  "features": ["Responsive cushioning", "Breathable mesh", "Durable outsole"],
  "rating": 4.7,
  "inventory": 45,
  "tags": ["running", "athletic", "comfortable", "lightweight"]
}
```

The dataset includes products from categories such as:
- Electronics (smartphones, laptops, headphones, etc.)
- Clothing (shirts, pants, dresses, etc.)
- Home goods (furniture, kitchenware, decor, etc.)
- Beauty & Personal Care (skincare, makeup, fragrances, etc.)
- Sports & Outdoors (equipment, apparel, accessories, etc.)

### Key Implementation Guidelines

#### LLM Integration
- You should use OpenAI's API (GPT-3.5-turbo is sufficient) or another LLM API of your choice
- Implement proper error handling for API calls
- Use appropriate context windows and token limits

#### Prompt Engineering
- Design prompts that effectively leverage product metadata and user preferences
- Ensure your prompts provide reasoning for recommendations
- Consider how to handle context limitations for larger product catalogs

#### API Design
- Create RESTful endpoints with proper request/response formats
- Implement appropriate error handling
- Consider performance and optimization

#### React Frontend
- Focus on clean, functional UI rather than elaborate designs
- Implement responsive components that adapt to different screen sizes
- Use React state management appropriately (useState, useContext, etc.)

### Stretch Goals (Optional)

If you complete the core requirements and want to demonstrate additional skills, consider implementing one or more of these stretch goals:

1. Add user authentication and profile persistence
2. Implement caching for LLM responses to improve performance
3. Add filtering and sorting options to the product catalog
4. Create A/B testing for different prompt strategies
5. Add unit and/or integration tests

### Evaluation Criteria

Your submission will be evaluated based on:

1. **Prompt Engineering Quality (30%)**
   - Effectiveness of prompts in generating relevant recommendations
   - Context handling and optimization
   - Clarity and usefulness of recommendation explanations

2. **API Design and Implementation (25%)**
   - RESTful API design and implementation
   - Error handling and edge cases
   - Code organization and structure

3. **Frontend Implementation (25%)**
   - Component architecture and organization
   - User experience and interface design
   - State management and data flow

4. **Code Quality (20%)**
   - Code readability and documentation
   - Proper use of version control (commit messages, organization)
   - Error handling and edge cases

### Submission Guidelines

1. **GitHub Repository**
   - Create a **public** GitHub repository with your implementation
   - Ensure your repository includes:
     - Complete source code for both frontend and backend
     - A comprehensive README with setup instructions
     - Documentation of your approach, especially for prompt engineering

2. **Deployment (Optional)**
   - If possible, deploy your application (e.g., Vercel, Netlify, Heroku)
   - Include the deployed URL in your README

3. **Submission Timeline**
   - Complete the assignment within 7 days of receiving it
   - Submit by **replying to the original assessment email** with:
     - GitHub repository link
     - Brief overview of your approach (1-2 paragraphs)
     - Any challenges you faced and how you overcame them
     - Time spent on the assignment

### Setup Instructions

#### Backend Setup
1. Navigate to the `backend` directory
2. Create a virtual environment: `python -m venv venv`
3. Activate the virtual environment:
   - Windows: `venv\Scripts\activate`
   - macOS/Linux: `source venv/bin/activate`
4. Install dependencies: `pip install -r requirements.txt`
5. Create a `.env` file based on `.env.example` and add your LLM API key
6. Run the application: `python app.py`

#### Frontend Setup
1. Navigate to the `frontend` directory
2. Install dependencies: `npm install`
3. Start the development server: `npm start`
4. The application should open at `http://localhost:3000`

### Notes and Tips

- **API Keys**: Never commit your API keys to GitHub. Use environment variables.
- **Time Management**: Focus on core functionality first, then enhance if time permits.
- **Documentation**: Document your approach, especially your prompt engineering strategy.
- **Code Quality**: Clean, well-organized code is more important than feature quantity.
- **Questions**: If you have questions, email recruiting@i95dev.com with "Question: AI Intern Take-Home" as the subject.

### Resources

- [OpenAI API Documentation](https://platform.openai.com/docs/api-reference)
- [Flask Documentation](https://flask.palletsprojects.com/)
- [React Documentation](https://reactjs.org/docs/getting-started.html)
- [Prompt Engineering Guide](https://www.promptingguide.ai/)

We're excited to see your implementation and approach! Good luck!
>>>>>>> e7d6377 (Initial commit)
